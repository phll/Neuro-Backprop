\relax 
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {random caption 1}}}{1}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {random caption 2}}}{1}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {random caption 1}}}{1}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(d)}{\ignorespaces {random caption 2}}}{1}}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Multicompartment-Neurons}{1}}
\newlabel{eq:soma}{{1}{1}}
\newlabel{eq:steady}{{2}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}PyraL-Network }{2}}
\newlabel{eq:dyn_hidden}{{6}{2}}
\newlabel{eq:apical}{{9}{2}}
\newlabel{eq:dyn_out}{{12}{2}}
\newlabel{fig:network}{{1.2}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}Learning-Rules}{3}}
\newlabel{eq:out_stead}{{14}{3}}
\newlabel{eq:basal_pyr}{{17}{4}}
\newlabel{eq:dend_int}{{20}{4}}
\newlabel{eq:delta_up}{{21}{4}}
\newlabel{eq:delta_ap}{{23}{4}}
\newlabel{eq:W_pi}{{26}{4}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.3.1}Self-predicting state}{4}}
\newlabel{eq:sps_pi}{{29}{4}}
\newlabel{eq:sps_ip}{{30}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4}Approximation of the Error-Backpropagation Algorithm}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.5}Steady-State-Approximation of the Network Dynamics (SteadNet)}{5}}
\newlabel{chap:steadnet}{{1.5}{5}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Experimental Results}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Basics}{5}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.1}Stability and Fix-Points}{5}}
\newlabel{fig:stability}{{2.1.1}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces \textbf  {Upper row}: Evolution of soma potentials of a simple 3-layer network with three neurons in total. Columns represent different network configurations and initial conditions and weights are kept fixed during the simulation. \textbf  {Lower row}: Derivative of the hidden pyramidial soma potential $u^P_{hid}$ fully expressed through $u^P_{hid}$ via the steady-state solution of the other soma potential (see main text). \textbf  {Details: } $g_A = g_{som} = 0.8$, $g_D = g_B = 1$, $g_l = 0.1$, $r_{in} = u^{target} = 1$, $dt = 0.001$}}{6}}
\newlabel{eq:fix_out}{{33}{6}}
\newlabel{eq:fix_inter}{{34}{6}}
\newlabel{eq:fix_pyr}{{35}{6}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.2}Basic Regression Task and Emergence of Self-Predicting-State}{7}}
\newlabel{fig:mimic}{{2.1.2}{7}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Output layer soma potentials and target potentials before training.}}}{7}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Output layer soma potentials and target potentials after training.}}}{7}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {MSQE validation error during training.}}}{7}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(d)}{\ignorespaces {Emergence of self-predicting-state during training starting from randomly initialized connections.}}}{7}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.3}Steady-State-Approximation}{8}}
\newlabel{fig:stead}{{2.1.3}{9}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(e)}{\ignorespaces {Deviation\footnotemark\nobreakspace {}of the simulated from the approximation soma potentials, when plasticity is switched off.}}}{9}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(f)}{\ignorespaces {Deviation of the simulated from the approximation soma potentials, when plasticity is switched off, but the network is initialized in the self-predicting state.}}}{9}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(g)}{\ignorespaces {Deviation of the simulated from the approximation weights, when plasticity is switched on.}}}{9}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(h)}{\ignorespaces {Deviation of the simulated from the approximation weights, when plasticity is switched on, but the network is initialized in the self-predicting state.}}}{9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}MNIST with SteadNet}{10}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}YinYang-Task}{10}}
\newlabel{fig:yinyang_vary}{{2.3}{11}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(i)}{\ignorespaces {Output layer soma potentials and target potentials before training.}}}{11}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(j)}{\ignorespaces {Output layer soma potentials and target potentials after training.}}}{11}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(k)}{\ignorespaces {MSQE validation error during training.}}}{11}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(l)}{\ignorespaces {Emergence of self-predicting-state during training starting from randomly initialized connections.}}}{11}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(m)}{\ignorespaces {Output layer soma potentials and target potentials before training.}}}{12}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(n)}{\ignorespaces {Output layer soma potentials and target potentials after training.}}}{12}}
